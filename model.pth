import numpy as np
from glob import glob
from PIL import Image
from PIL import ImageFile
import cv2
import matplotlib.pyplot as plt
from tqdm import tqdm

import torch
import torchvision.models as models
import torchvision.transforms as transforms
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import datasets # Needed for ImageFolder

# --- Configuration ---
# Set to True if you want to allow truncated images to be loaded
ImageFile.LOAD_TRUNCATED_IMAGES = True

# Check if CUDA (GPU) is available
use_cuda = torch.cuda.is_available()
print(f"CUDA available: {use_cuda}")

# Define a variable for the number of dog breeds
# You can get this dynamically from your dataset later if needed
NUM_DOG_BREEDS = 133

# --- Step 0: Import Datasets ---
# Load filenames for human and dog images
human_files = np.array(glob("/data/lfw/*/*"))
dog_files = np.array(glob("/data/dog_images/*/*/*"))

print(f'There are {len(human_files)} total human images.')
print(f'There are {len(dog_files)} total dog images.')

# --- Step 1: Detect Humans (Haar Cascade) ---
# Load pre-trained face detector
face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')

def face_detector(img_path):
    """
    Returns True if a human face is detected in the image, False otherwise.
    Args:
        img_path (str): Path to the image file.
    Returns:
        bool: True if face detected, False otherwise.
    """
    img = cv2.imread(img_path)
    if img is None:
        print(f"Warning: Could not read image at {img_path}")
        return False
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray)
    return len(faces) > 0

# Test performance (optional, uncomment to run)
# human_files_short = human_files[:100]
# dog_files_short = dog_files[:100]
#
# n_face_human_files = sum([face_detector(human_files_short[i]) for i in range(len(human_files_short))])
# n_face_dog_files = sum([face_detector(dog_files_short[i]) for i in range(len(dog_files_short))])
#
# print(f'% of human face in human files: {n_face_human_files/100.0}')
# print(f'% of human face in dog files: {n_face_dog_files/100.0}')

# --- Step 2: Detect Dogs (Pre-trained VGG-16) ---

# Load pre-trained VGG16 model
VGG16 = models.vgg16(pretrained=True)
if use_cuda:
    VGG16 = VGG16.cuda()
# print(VGG16) # Uncomment to see the model architecture

def preprocess_img(img_path):
    """
    Preprocesses an image for PyTorch pre-trained models.
    Resizes, crops, converts to tensor, and normalizes.
    Args:
        img_path (str): Path to the image file.
    Returns:
        torch.Tensor: Preprocessed image tensor, ready for model input.
    """
    transform = transforms.Compose([
     transforms.Resize(256),
     transforms.CenterCrop(224),
     transforms.ToTensor(),
     transforms.Normalize(
     mean=[0.485, 0.456, 0.406],
     std=[0.229, 0.224, 0.225]
     )])

    img = Image.open(img_path).convert('RGB') # Ensure image is RGB
    img_t = transform(img)
    batch_t = torch.unsqueeze(img_t, 0)
    if use_cuda:
        batch_t = batch_t.cuda()
    return batch_t

def VGG16_predict(img_path):
    """
    Use pre-trained VGG-16 model to obtain index corresponding to
    predicted ImageNet class for image at specified path.
    Args:
        img_path (str): path to an image
    Returns:
        int: Index corresponding to VGG-16 model's prediction (0-999).
    """
    VGG16.eval() # Set model to evaluation mode
    batch_t = preprocess_img(img_path)
    with torch.no_grad(): # Disable gradient calculation for inference
        out = VGG16(batch_t)
    return out.argmax().item() # .item() to get the Python number from tensor

def dog_detector(img_path):
    """
    Returns True if a dog is detected in the image using VGG-16, False otherwise.
    ImageNet classes 151-268 (inclusive) correspond to dogs.
    Args:
        img_path (str): Path to the image file.
    Returns:
        bool: True if dog detected, False otherwise.
    """
    breed_idx = VGG16_predict(img_path)
    flag_detected = breed_idx in range(151, 269) # 269 is exclusive in range
    return flag_detected

# Test dog detector (optional, uncomment to run)
# print(f"Is dog_files[0] a dog? {dog_detector(dog_files[0])}")
# n_dog_in_human_files = [dog_detector(human_files_short[i]) for i in tqdm(range(len(human_files_short)), desc="Checking human files for dogs")]
# print(f'proportion of dog face in human files: {sum(n_dog_in_human_files)/len(human_files_short)}')
# n_dog_in_dog_files = [dog_detector(dog_files_short[i]) for i in tqdm(range(len(dog_files_short)), desc="Checking dog files for dogs")]
# print(f'proportion of dog face in dog files: {sum(n_dog_in_dog_files)/len(dog_files_short)}')


# --- Step 3 & 4: Data Loaders for Dog Dataset ---
# Data transformations for training, validation, and test sets
transform = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize(size=(224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
}

# Load datasets
train_data = datasets.ImageFolder(root="/data/dog_images/train", transform=transform['train'])
val_data = datasets.ImageFolder(root="/data/dog_images/valid", transform=transform['val'])
test_data = datasets.ImageFolder(root="/data/dog_images/test", transform=transform['test'])

batch_size = 32

# Create DataLoaders
train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_data, batch_size=batch_size)
test_loader = DataLoader(test_data, batch_size=batch_size)

# Dict for loaders
loaders_scratch = {
    'train': train_loader,
    'val': val_loader,
    'test': test_loader
}
# Transfer learning will use the same loaders
loaders_transfer = loaders_scratch.copy()

# List of class names for breed prediction
class_names = [item[4:].replace("_", " ") for item in train_data.classes]
NUM_DOG_BREEDS = len(class_names)
print(f"Number of dog breeds: {NUM_DOG_BREEDS}")

# --- Step 3: Create a CNN to Classify Dog Breeds (from Scratch) ---
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        # Convolutional layers
        self.cnn_layers = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2), # Output size: (32, 112, 112)

            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2), # Output size: (64, 56, 56)

            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2), # Output size: (128, 28, 28)

            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2), # Output size: (256, 14, 14)

            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2), # Output size: (512, 7, 7)
        )

        # Calculate input features for the first linear layer
        # For 224x224 input, after 5 MaxPool2d layers (each halves dimensions)
        # 224 -> 112 -> 56 -> 28 -> 14 -> 7
        # So, the output will be (512 channels, 7 height, 7 width)
        # 512 * 7 * 7 = 25088
        # The original code had 401408, which likely corresponds to 32 * 112 * 112
        # if only one MaxPool2d was used before flattening, or a different initial
        # architecture was experimented with. Sticking to a more standard CNN progression.
        # Let's use 25088 based on the common VGG-like progression.
        self.linear_layers = nn.Sequential(
            nn.Dropout(p=0.5),
            nn.Linear(512 * 7 * 7, 512), # Corrected input feature size
            nn.BatchNorm1d(512),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.5),
            nn.Linear(512, NUM_DOG_BREEDS), # Output to 133 dog breeds
        )

    def forward(self, x):
        x = self.cnn_layers(x)
        x = x.view(x.size(0), -1) # Flatten the output
        x = self.linear_layers(x)
        return F.log_softmax(x, dim=1) # Specify dim for log_softmax

# Instantiate the CNN from scratch model
model_scratch = Net()
if use_cuda:
    model_scratch.cuda()

# Loss function and optimizer for scratch model
criterion_scratch = nn.CrossEntropyLoss()
optimizer_scratch = optim.SGD(model_scratch.parameters(), lr=0.005, momentum=0.9)


# --- Training and Validation Function ---
def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):
    """
    Trains and validates a PyTorch model.
    Args:
        n_epochs (int): Number of training epochs.
        loaders (dict): Dictionary containing 'train' and 'val' DataLoaders.
        model (nn.Module): The neural network model to train.
        optimizer (torch.optim.Optimizer): The optimizer for model parameters.
        criterion (torch.nn.Module): The loss function.
        use_cuda (bool): True if GPU should be used, False otherwise.
        save_path (str): File path to save the best model.
    Returns:
        nn.Module: The trained model.
    """
    valid_loss_min = np.Inf

    for epoch in range(1, n_epochs + 1):
        train_loss = 0.0
        valid_loss = 0.0

        # Train the model
        model.train()
        for batch_idx, (data, target) in enumerate(tqdm(loaders['train'], desc=f"Epoch {epoch} Training")):
            if use_cuda:
                data, target = data.cuda(), target.cuda()
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))

        # Validate the model
        model.eval()
        for batch_idx, (data, target) in enumerate(tqdm(loaders['val'], desc=f"Epoch {epoch} Validation")):
            if use_cuda:
                data, target = data.cuda(), target.cuda()
            with torch.no_grad(): # Disable gradient calculation for validation
                output = model(data)
                loss = criterion(output, target)
            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))

        print(f'\nEpoch: {epoch} \tTraining Loss: {train_loss:.6f} \tValidation Loss: {valid_loss:.6f}')

        # Save the model if validation loss has decreased
        if valid_loss <= valid_loss_min:
            print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model...')
            torch.save(model.state_dict(), save_path)
            valid_loss_min = valid_loss
    return model

# --- Testing Function ---
def test(loaders, model, criterion, use_cuda):
    """
    Tests a PyTorch model on the test dataset.
    Args:
        loaders (dict): Dictionary containing 'test' DataLoader.
        model (nn.Module): The trained neural network model.
        criterion (torch.nn.Module): The loss function.
        use_cuda (bool): True if GPU should be used, False otherwise.
    """
    test_loss = 0.
    correct = 0.
    total = 0.

    model.eval() # Set model to evaluation mode
    for batch_idx, (data, target) in enumerate(tqdm(loaders['test'], desc="Testing")):
        if use_cuda:
            data, target = data.cuda(), target.cuda()
        with torch.no_grad(): # Disable gradient calculation for inference
            output = model(data)
            loss = criterion(output, target)
        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))
        pred = output.data.max(1, keepdim=True)[1] # Get the index of the max log-probability
        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())
        total += data.size(0)

    print(f'\nTest Loss: {test_loss:.6f}\n')
    print(f'\nTest Accuracy: {100. * correct / total:.2f}% ({int(correct)}/{int(total)})')

# --- Train and Test CNN from Scratch (uncomment to run) ---
# print("\n--- Training CNN from Scratch ---")
# n_epochs_scratch = 20
# model_scratch = train(n_epochs_scratch, loaders_scratch, model_scratch, optimizer_scratch,
#                       criterion_scratch, use_cuda, 'model_scratch.pt')
#
# # Load the model that got the best validation accuracy
# model_scratch.load_state_dict(torch.load('model_scratch.pt'))
#
# print("\n--- Testing CNN from Scratch ---")
# test(loaders_scratch, model_scratch, criterion_scratch, use_cuda)


# --- Step 4: Create a CNN to Classify Dog Breeds (using Transfer Learning) ---

# Load pre-trained VGG16 model
model_transfer = models.vgg16(pretrained=True)

# Freeze VGG feature extraction layers
for param in model_transfer.features.parameters():
    param.requires_grad = False

# Replace the classifier's last layer
# The last layer of VGG16's classifier (model_transfer.classifier[6]) is a Linear layer
# Its input features (in_features) must match the output features of the previous layer.
# Its output features (out_features) must match our number of dog breeds.
n_inputs = model_transfer.classifier[6].in_features
model_transfer.classifier[6] = nn.Linear(n_inputs, NUM_DOG_BREEDS)

if use_cuda:
    model_transfer = model_transfer.cuda()

# Loss function and optimizer for transfer learning model
criterion_transfer = nn.CrossEntropyLoss()
# Only optimize the parameters of the newly added classifier layer
optimizer_transfer = optim.SGD(model_transfer.classifier.parameters(), lr=0.005, momentum=0.9)


# --- Train and Test Transfer Learning Model (uncomment to run) ---
# print("\n--- Training CNN with Transfer Learning (VGG16) ---")
# n_epochs_transfer = 20 # Can adjust based on previous output
# model_transfer = train(n_epochs_transfer, loaders_transfer, model_transfer, optimizer_transfer,
#                        criterion_transfer, use_cuda, 'model_transfer.pt')
#
# # Load the model that got the best validation accuracy
# model_transfer.load_state_dict(torch.load('model_transfer.pt'))
#
# print("\n--- Testing CNN with Transfer Learning (VGG16) ---")
# test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)

# --- Step 5: Write your Algorithm ---

def predict_breed_transfer(img_path):
    """
    Predicts the dog breed using the trained transfer learning model.
    Args:
        img_path (str): Path to the image file.
    Returns:
        str: Predicted dog breed name.
    """
    model_transfer.eval() # Set model to evaluation mode
    batch_t = preprocess_img(img_path) # Reuse preprocess_img from Step 2
    with torch.no_grad():
        out = model_transfer(batch_t)
    breed_index = out.argmax().item()
    return class_names[breed_index]

def run_dog_app(img_path):
    """
    Main algorithm for the Dog Identification App.
    Detects human/dog and predicts breed if a dog or human is detected.
    Args:
        img_path (str): Path to the image file.
    Returns:
        str: A message indicating the detection and/or predicted breed.
    """
    if face_detector(img_path):
        # Image contains a human
        predicted_breed = predict_breed_transfer(img_path)
        return (f"Hello, human! You look like a {predicted_breed}. "
                f"Here's the image:\n{img_path}")
    elif dog_detector(img_path):
        # Image contains a dog
        predicted_breed = predict_breed_transfer(img_path)
        return (f"Hello, dog! Your breed is likely a {predicted_breed}. "
                f"Here's the image:\n{img_path}")
    else:
        # Neither human nor dog detected
        return (f"Error: Neither a human nor a dog was detected in the image. "
                f"Please try with another image.\n{img_path}")

# --- Step 6: Test Your Algorithm (Example usage - uncomment to run) ---

# To run these tests, you would first need to train and save 'model_transfer.pt'
# or uncomment the training blocks above.

# Example usage:
# print("\n--- Testing the full algorithm ---")
#
# # Assuming you have some sample images in your environment:
# # Test with a human image
# human_test_image = human_files[np.random.randint(len(human_files))]
# print(f"\nProcessing human image: {human_test_image}")
# print(run_dog_app(human_test_image))
# Image.open(human_test_image).show() # Requires GUI environment
#
# # Test with a dog image
# dog_test_image = dog_files[np.random.randint(len(dog_files))]
# print(f"\nProcessing dog image: {dog_test_image}")
# print(run_dog_app(dog_test_image))
# Image.open(dog_test_image).show() # Requires GUI environment
#
# # Test with an image that is neither (e.g., an object or a landscape)
# # You would need to provide a path to such an image for a real test
# # For demonstration, let's pick one that might not detect either for now
# # Replace with an actual "neither" image path for proper testing
# neither_test_image = "/path/to/an/image/of/a/chair.jpg" # Placeholder
# # print(f"\nProcessing 'neither' image: {neither_test_image}")
# # print(run_dog_app(neither_test_image))
